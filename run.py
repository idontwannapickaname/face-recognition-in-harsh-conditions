# run.py

import torch
import numpy as np
import os
from collections import defaultdict
from torch.utils.data import DataLoader
from typing import Dict, Any
from module.training import build_dataloaders, pretrain, train
from module.data_utils import load_image_paths
from module.datasets import PairedLightDarkDataset
from module.models import load_model, save_model, ContrastiveBackbone, ContrastiveModel
from module.evaluation import eval_model

SEED = 200
# Ch·ªçn thi·∫øt b·ªã: CUDA n·∫øu c√≥, ng∆∞·ª£c l·∫°i l√† CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Device: {device}")
torch.manual_seed(SEED)
np.random.seed(SEED)

# Hyperparameters
# D·ªØ li·ªáu
DATA_ROOT = "data"
TRN_SPLITS = ['normal', 'darken_normal'] # T·∫≠p normal v√† ·∫£nh t·ªëi gi·∫£ (cho finetune)
TST_SPLITS = ['low_light']              # T·∫≠p low_light ƒë·ªÉ chia Val/Test
LOW_LIGHT_SPLIT_PCT = 0.5               # 50% low_light cho train, 25% val, 25% test
BATCH_SIZE = 8

# Pre-training Contrastive
PRETRAIN_EPOCHS = 50 
PRETRAIN_PATIENCE = 15
PRETRAIN_LR = 1e-3
PRETRAIN_BATCH_SIZE = 256
PRETRAIN_BB_MODEL_PATH = 'models/best_bb_state_dict.pt'

# Fine-tuning
FINETUNE_EPOCHS = 60
FINETUNE_PATIENCE = 5
FINETUNE_LR = 1e-3
LR_DROP_RATIO = 0.1
UNFREEZE_EPOCH = 5
UNFREEZE_LAYERS = 2 # M·ªü kh√≥a 2 layer cu·ªëi c·ªßa backbone
FINETUNE_MODEL_PATH = 'models/best_finetune_model.pt'
EMBED_DIM = 512

print("\n--- 0. Chu·∫©n b·ªã DataLoaders cho Finetune (Classification) ---")
try:
    trn_ld, val_ld, tst_ld, name_id_map = build_dataloaders(
        trn_split_list=TRN_SPLITS, 
        tst_split_list=TST_SPLITS, 
        root=DATA_ROOT, 
        pct=LOW_LIGHT_SPLIT_PCT, 
        batch_size=BATCH_SIZE, 
        should_tta=True, # B·∫≠t TTA cho t·∫≠p Test
        seed=SEED
    )
    num_classes = len(name_id_map)
    id_name_map = {v: k for k, v in name_id_map.items()}
    print(f"‚úÖ DataLoaders ƒë√£ s·∫µn s√†ng.")
    print(f"S·ªë l∆∞·ª£ng l·ªõp (ng∆∞·ªùi): {num_classes}")
    print(f"K√≠ch th∆∞·ªõc t·∫≠p Train/Val/Test: {len(trn_ld.dataset)}/{len(val_ld.dataset)}/{len(tst_ld.dataset)}")

except Exception as e:
    print(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu. ƒê·∫£m b·∫£o c·∫•u tr√∫c th∆∞ m·ª•c '{DATA_ROOT}/...' l√† ch√≠nh x√°c.")
    print(f"L·ªói: {e}")
    exit()

print("\n--- 1. B·∫Øt ƒë·∫ßu Pre-training Contrastive (Light-Dark Pairs) ---")

try:
    light_paths, light_ids, dark_paths, dark_ids, _ = load_image_paths(['normal'], ['darken_normal_for_finetune'], root=DATA_ROOT)
    light_map = defaultdict(list)
    dark_map = defaultdict(list)
    for id, path in zip(light_ids, light_paths):
        light_map[id].append(path)
    for id, path in zip(dark_ids, dark_paths):
        dark_map[id].append(path)

    pretrn_ds = PairedLightDarkDataset(light_map, dark_map, seed=SEED)
    pretrn_ld = DataLoader(pretrn_ds, batch_size=PRETRAIN_BATCH_SIZE, shuffle=True) 

    # Kh·ªüi t·∫°o Contrastive Backbone
    pretrained_bb = ContrastiveBackbone(embed_dim=EMBED_DIM)

    # Hu·∫•n luy·ªán
    best_bb = pretrain(
        pretrained_bb,
        pretrn_ld,
        num_epochs=PRETRAIN_EPOCHS,
        lr=PRETRAIN_LR,
        patience=PRETRAIN_PATIENCE,
        device=str(device),
        use_pretrain=True,
        use_early_stopping=True,
    )

    # L∆∞u checkpoint c·ªßa backbone ƒë√£ pre-train t·ªët nh·∫•t
    save_model(best_bb, PRETRAIN_BB_MODEL_PATH)
    print("--- K·∫øt th√∫c Pre-training ---")

except ValueError as e:
    print(f"‚ö†Ô∏è B·ªè qua Pre-training do l·ªói d·ªØ li·ªáu: {e}")
    # N·∫øu kh√¥ng th·ªÉ pretrain, t·∫£i l·∫°i checkpoint n·∫øu c√≥
    try:
        if os.path.exists(PRETRAIN_BB_MODEL_PATH.replace('.pt', '_state_dict.pt')):
            print(f"ƒêang t·∫£i backbone ƒë√£ l∆∞u t·ª´ {PRETRAIN_BB_MODEL_PATH}...")
            best_bb = ContrastiveBackbone(embed_dim=EMBED_DIM)
            best_bb = load_model(best_bb, PRETRAIN_BB_MODEL_PATH)
        else:
            print("Kh√¥ng c√≥ checkpoint pre-train n√†o ƒë∆∞·ª£c t√¨m th·∫•y. S·ª≠ d·ª•ng backbone kh·ªüi t·∫°o ng·∫´u nhi√™n.")
            best_bb = ContrastiveBackbone(embed_dim=EMBED_DIM) # T·∫£i l·∫°i model ban ƒë·∫ßu
            
    except Exception as e:
        print(f"L·ªói khi t·∫£i checkpoint: {e}")
        exit()


print("\n--- 2. B·∫Øt ƒë·∫ßu Fine-tuning (Simple Head) ---")

# Kh·ªüi t·∫°o m√¥ h√¨nh Finetune v·ªõi backbone ƒë√£ pre-train (ho·∫∑c ƒë√£ t·∫£i)
finetune_model = ContrastiveModel(
    pretrained_backbone=best_bb, 
    embed_dim=EMBED_DIM, 
    num_classes=num_classes, 
    num_unfreeze_layers=UNFREEZE_LAYERS
)

# Hu·∫•n luy·ªán Finetune
best_finetune_model = train(
    finetune_model, 
    trn_ld, 
    val_ld, 
    id_name_map, 
    lr=FINETUNE_LR, 
    lr_drop_ratio=LR_DROP_RATIO, 
    num_epochs=FINETUNE_EPOCHS, 
    unfreeze_epoch=UNFREEZE_EPOCH, 
    num_layers_unfreeze=UNFREEZE_LAYERS, 
    patience=FINETUNE_PATIENCE, 
    device=device,
    with_archead=False
)

# L∆∞u checkpoint c·ªßa m√¥ h√¨nh finetune t·ªët nh·∫•t
save_model(best_finetune_model, FINETUNE_MODEL_PATH)
print("--- K·∫øt th√∫c Fine-tuning ---")

print("\n--- 3. ƒê√°nh gi√° cu·ªëi c√πng tr√™n t·∫≠p Test ---")

# ƒê√°nh gi√° v·ªõi TTA (Test-Time Augmentation)
test_results = eval_model(
    best_finetune_model, 
    tst_ld, 
    id_name_map, 
    device=device,
    with_archead=False # Gi·∫£ ƒë·ªãnh kh√¥ng d√πng ArcFace cho m√¥ h√¨nh n√†y
)

print("\n=============================================")
print("             K·∫æT QU·∫¢ TEST CU·ªêI C√ôNG           ")
print("=============================================")
print(f"üî• Overall Accuracy (C√≥ TTA): {test_results['overall_acc']:.4f}")
print(f"üî• Balanced Accuracy: {test_results['balanced_acc']:.4f}")
print(f"Loss: {test_results['val_loss']:.4f}")
print("-" * 45)
print("Metrics chi ti·∫øt:")
print(f"F1-Score (Weighted): {test_results['f1_weighted']:.4f}")
print(f"Precision (Weighted): {test_results['precision_weighted']:.4f}")
print(f"Recall (Weighted): {test_results['recall_weighted']:.4f}")
print("-" * 45)
print("Accuracy theo l·ªõp:")
for person, acc in test_results['class_acc'].items():
     print(f"  {person:<10}: {acc:.4f}")
print("-" * 45)
print("Confusion Matrix:\n", test_results['confusion_matrix'])
print("=============================================")